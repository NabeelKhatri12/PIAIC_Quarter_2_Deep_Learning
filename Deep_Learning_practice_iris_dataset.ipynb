{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical # hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width     variety\n",
       "48            5.3          3.7           1.5          0.2      Setosa\n",
       "106           4.9          2.5           4.5          1.7   Virginica\n",
       "93            5.0          2.3           3.3          1.0  Versicolor\n",
       "87            6.3          2.3           4.4          1.3  Versicolor\n",
       "27            5.2          3.5           1.5          0.2      Setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.sample(frac = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.3, 3.7, 1.5, 0.2, 'Setosa'],\n",
       "       [4.9, 2.5, 4.5, 1.7, 'Virginica'],\n",
       "       [5.0, 2.3, 3.3, 1.0, 'Versicolor'],\n",
       "       [6.3, 2.3, 4.4, 1.3, 'Versicolor'],\n",
       "       [5.2, 3.5, 1.5, 0.2, 'Setosa'],\n",
       "       [7.2, 3.0, 5.8, 1.6, 'Virginica'],\n",
       "       [4.7, 3.2, 1.6, 0.2, 'Setosa'],\n",
       "       [5.7, 2.8, 4.5, 1.3, 'Versicolor'],\n",
       "       [5.0, 3.2, 1.2, 0.2, 'Setosa'],\n",
       "       [6.0, 2.2, 5.0, 1.5, 'Virginica'],\n",
       "       [7.9, 3.8, 6.4, 2.0, 'Virginica'],\n",
       "       [5.5, 4.2, 1.4, 0.2, 'Setosa'],\n",
       "       [5.1, 3.8, 1.5, 0.3, 'Setosa'],\n",
       "       [7.4, 2.8, 6.1, 1.9, 'Virginica'],\n",
       "       [5.0, 3.0, 1.6, 0.2, 'Setosa'],\n",
       "       [5.7, 2.8, 4.1, 1.3, 'Versicolor'],\n",
       "       [7.6, 3.0, 6.6, 2.1, 'Virginica'],\n",
       "       [6.2, 2.2, 4.5, 1.5, 'Versicolor'],\n",
       "       [6.3, 3.4, 5.6, 2.4, 'Virginica'],\n",
       "       [6.7, 3.3, 5.7, 2.5, 'Virginica'],\n",
       "       [6.8, 3.0, 5.5, 2.1, 'Virginica'],\n",
       "       [4.9, 3.1, 1.5, 0.2, 'Setosa'],\n",
       "       [7.3, 2.9, 6.3, 1.8, 'Virginica'],\n",
       "       [5.6, 2.8, 4.9, 2.0, 'Virginica'],\n",
       "       [5.1, 3.8, 1.6, 0.2, 'Setosa'],\n",
       "       [4.9, 3.6, 1.4, 0.1, 'Setosa'],\n",
       "       [5.8, 2.7, 5.1, 1.9, 'Virginica'],\n",
       "       [4.6, 3.2, 1.4, 0.2, 'Setosa'],\n",
       "       [6.3, 2.5, 4.9, 1.5, 'Versicolor'],\n",
       "       [5.1, 3.8, 1.9, 0.4, 'Setosa'],\n",
       "       [5.8, 2.6, 4.0, 1.2, 'Versicolor'],\n",
       "       [6.7, 2.5, 5.8, 1.8, 'Virginica'],\n",
       "       [4.6, 3.1, 1.5, 0.2, 'Setosa'],\n",
       "       [6.5, 3.0, 5.5, 1.8, 'Virginica'],\n",
       "       [7.7, 2.8, 6.7, 2.0, 'Virginica'],\n",
       "       [6.7, 3.0, 5.2, 2.3, 'Virginica'],\n",
       "       [4.7, 3.2, 1.3, 0.2, 'Setosa'],\n",
       "       [5.2, 4.1, 1.5, 0.1, 'Setosa'],\n",
       "       [5.5, 2.3, 4.0, 1.3, 'Versicolor'],\n",
       "       [5.6, 2.9, 3.6, 1.3, 'Versicolor'],\n",
       "       [5.9, 3.0, 4.2, 1.5, 'Versicolor'],\n",
       "       [6.9, 3.1, 4.9, 1.5, 'Versicolor'],\n",
       "       [5.1, 3.5, 1.4, 0.3, 'Setosa'],\n",
       "       [6.3, 2.5, 5.0, 1.9, 'Virginica'],\n",
       "       [5.6, 3.0, 4.1, 1.3, 'Versicolor'],\n",
       "       [6.6, 3.0, 4.4, 1.4, 'Versicolor'],\n",
       "       [4.6, 3.4, 1.4, 0.3, 'Setosa'],\n",
       "       [4.5, 2.3, 1.3, 0.3, 'Setosa'],\n",
       "       [5.4, 3.9, 1.3, 0.4, 'Setosa'],\n",
       "       [4.8, 3.0, 1.4, 0.1, 'Setosa'],\n",
       "       [5.7, 4.4, 1.5, 0.4, 'Setosa'],\n",
       "       [5.8, 2.7, 3.9, 1.2, 'Versicolor'],\n",
       "       [6.4, 2.8, 5.6, 2.1, 'Virginica'],\n",
       "       [7.7, 3.0, 6.1, 2.3, 'Virginica'],\n",
       "       [4.8, 3.0, 1.4, 0.3, 'Setosa'],\n",
       "       [5.0, 3.4, 1.6, 0.4, 'Setosa'],\n",
       "       [6.3, 3.3, 6.0, 2.5, 'Virginica'],\n",
       "       [5.1, 2.5, 3.0, 1.1, 'Versicolor'],\n",
       "       [4.6, 3.6, 1.0, 0.2, 'Setosa'],\n",
       "       [7.2, 3.6, 6.1, 2.5, 'Virginica'],\n",
       "       [5.7, 2.6, 3.5, 1.0, 'Versicolor'],\n",
       "       [7.0, 3.2, 4.7, 1.4, 'Versicolor'],\n",
       "       [6.0, 2.2, 4.0, 1.0, 'Versicolor'],\n",
       "       [6.9, 3.2, 5.7, 2.3, 'Virginica'],\n",
       "       [6.5, 3.2, 5.1, 2.0, 'Virginica'],\n",
       "       [5.5, 3.5, 1.3, 0.2, 'Setosa'],\n",
       "       [5.0, 3.5, 1.3, 0.3, 'Setosa'],\n",
       "       [6.9, 3.1, 5.4, 2.1, 'Virginica'],\n",
       "       [5.1, 3.4, 1.5, 0.2, 'Setosa'],\n",
       "       [6.5, 3.0, 5.8, 2.2, 'Virginica'],\n",
       "       [6.7, 3.1, 4.4, 1.4, 'Versicolor'],\n",
       "       [4.8, 3.1, 1.6, 0.2, 'Setosa'],\n",
       "       [6.2, 2.8, 4.8, 1.8, 'Virginica'],\n",
       "       [5.4, 3.4, 1.7, 0.2, 'Setosa'],\n",
       "       [4.9, 2.4, 3.3, 1.0, 'Versicolor'],\n",
       "       [7.1, 3.0, 5.9, 2.1, 'Virginica'],\n",
       "       [6.1, 3.0, 4.9, 1.8, 'Virginica'],\n",
       "       [6.7, 3.0, 5.0, 1.7, 'Versicolor'],\n",
       "       [4.3, 3.0, 1.1, 0.1, 'Setosa'],\n",
       "       [6.2, 3.4, 5.4, 2.3, 'Virginica'],\n",
       "       [6.4, 3.2, 4.5, 1.5, 'Versicolor'],\n",
       "       [5.2, 2.7, 3.9, 1.4, 'Versicolor'],\n",
       "       [6.1, 2.9, 4.7, 1.4, 'Versicolor'],\n",
       "       [7.2, 3.2, 6.0, 1.8, 'Virginica'],\n",
       "       [5.0, 2.0, 3.5, 1.0, 'Versicolor'],\n",
       "       [4.9, 3.1, 1.5, 0.1, 'Setosa'],\n",
       "       [5.4, 3.4, 1.5, 0.4, 'Setosa'],\n",
       "       [4.9, 3.0, 1.4, 0.2, 'Setosa'],\n",
       "       [6.3, 3.3, 4.7, 1.6, 'Versicolor'],\n",
       "       [5.7, 3.8, 1.7, 0.3, 'Setosa'],\n",
       "       [6.4, 2.7, 5.3, 1.9, 'Virginica'],\n",
       "       [6.0, 2.7, 5.1, 1.6, 'Versicolor'],\n",
       "       [5.2, 3.4, 1.4, 0.2, 'Setosa'],\n",
       "       [6.7, 3.1, 4.7, 1.5, 'Versicolor'],\n",
       "       [5.5, 2.4, 3.7, 1.0, 'Versicolor'],\n",
       "       [5.9, 3.2, 4.8, 1.8, 'Versicolor'],\n",
       "       [5.8, 2.7, 5.1, 1.9, 'Virginica'],\n",
       "       [6.0, 2.9, 4.5, 1.5, 'Versicolor'],\n",
       "       [5.4, 3.9, 1.7, 0.4, 'Setosa'],\n",
       "       [5.1, 3.5, 1.4, 0.2, 'Setosa'],\n",
       "       [4.4, 3.0, 1.3, 0.2, 'Setosa'],\n",
       "       [5.6, 2.5, 3.9, 1.1, 'Versicolor'],\n",
       "       [6.1, 2.8, 4.7, 1.2, 'Versicolor'],\n",
       "       [5.0, 3.5, 1.6, 0.6, 'Setosa'],\n",
       "       [6.8, 2.8, 4.8, 1.4, 'Versicolor'],\n",
       "       [6.7, 3.1, 5.6, 2.4, 'Virginica'],\n",
       "       [6.5, 2.8, 4.6, 1.5, 'Versicolor'],\n",
       "       [6.7, 3.3, 5.7, 2.1, 'Virginica'],\n",
       "       [6.1, 2.6, 5.6, 1.4, 'Virginica'],\n",
       "       [6.4, 2.8, 5.6, 2.2, 'Virginica'],\n",
       "       [5.7, 2.9, 4.2, 1.3, 'Versicolor'],\n",
       "       [5.6, 2.7, 4.2, 1.3, 'Versicolor'],\n",
       "       [5.1, 3.7, 1.5, 0.4, 'Setosa'],\n",
       "       [6.3, 2.8, 5.1, 1.5, 'Virginica'],\n",
       "       [4.4, 2.9, 1.4, 0.2, 'Setosa'],\n",
       "       [4.8, 3.4, 1.9, 0.2, 'Setosa'],\n",
       "       [5.1, 3.3, 1.7, 0.5, 'Setosa'],\n",
       "       [6.1, 2.8, 4.0, 1.3, 'Versicolor'],\n",
       "       [5.9, 3.0, 5.1, 1.8, 'Virginica'],\n",
       "       [5.5, 2.4, 3.8, 1.1, 'Versicolor'],\n",
       "       [6.5, 3.0, 5.2, 2.0, 'Virginica'],\n",
       "       [7.7, 3.8, 6.7, 2.2, 'Virginica'],\n",
       "       [5.6, 3.0, 4.5, 1.5, 'Versicolor'],\n",
       "       [4.4, 3.2, 1.3, 0.2, 'Setosa'],\n",
       "       [5.4, 3.0, 4.5, 1.5, 'Versicolor'],\n",
       "       [5.5, 2.6, 4.4, 1.2, 'Versicolor'],\n",
       "       [6.1, 3.0, 4.6, 1.4, 'Versicolor'],\n",
       "       [5.0, 3.3, 1.4, 0.2, 'Setosa'],\n",
       "       [5.0, 3.6, 1.4, 0.2, 'Setosa'],\n",
       "       [6.4, 3.2, 5.3, 2.3, 'Virginica'],\n",
       "       [6.4, 3.1, 5.5, 1.8, 'Virginica'],\n",
       "       [7.7, 2.6, 6.9, 2.3, 'Virginica'],\n",
       "       [6.9, 3.1, 5.1, 2.3, 'Virginica'],\n",
       "       [5.8, 2.7, 4.1, 1.0, 'Versicolor'],\n",
       "       [5.7, 2.5, 5.0, 2.0, 'Virginica'],\n",
       "       [5.4, 3.7, 1.5, 0.2, 'Setosa'],\n",
       "       [6.3, 2.9, 5.6, 1.8, 'Virginica'],\n",
       "       [5.7, 3.0, 4.2, 1.2, 'Versicolor'],\n",
       "       [5.5, 2.5, 4.0, 1.3, 'Versicolor'],\n",
       "       [6.8, 3.2, 5.9, 2.3, 'Virginica'],\n",
       "       [6.3, 2.7, 4.9, 1.8, 'Virginica'],\n",
       "       [6.0, 3.4, 4.5, 1.6, 'Versicolor'],\n",
       "       [4.8, 3.4, 1.6, 0.2, 'Setosa'],\n",
       "       [5.8, 4.0, 1.2, 0.2, 'Setosa'],\n",
       "       [6.6, 2.9, 4.6, 1.3, 'Versicolor'],\n",
       "       [6.4, 2.9, 4.3, 1.3, 'Versicolor'],\n",
       "       [6.2, 2.9, 4.3, 1.3, 'Versicolor'],\n",
       "       [5.0, 3.4, 1.5, 0.2, 'Setosa'],\n",
       "       [6.0, 3.0, 4.8, 1.8, 'Virginica'],\n",
       "       [5.8, 2.8, 5.1, 2.4, 'Virginica']], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = df.values\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing to differ independent and dependent variable\n",
    "val_x = iris[:20, :4].astype(float)\n",
    "val_y = iris[:20, 4]\n",
    "\n",
    "x_train = iris[20: 110, :4].astype(float)\n",
    "y_train = iris[20: 110, 4]\n",
    "\n",
    "x_test = iris[110: , :4].astype(float)\n",
    "y_test = iris[110: , 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 4), (20,), (90, 4), (90,), (40, 4), (40,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape, val_y.shape, x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# encode class values as integers\n",
    "encoder= LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(y_train)\n",
    "encoded_y_train = tensorflow.keras.utils.to_categorical(encoded_Y)\n",
    "\n",
    "encoded_Y = encoder.fit_transform(y_test)\n",
    "encoded_y_test = tensorflow.keras.utils.to_categorical(encoded_Y)\n",
    "\n",
    "encoded_Y = encoder.fit_transform(val_y)\n",
    "encoded_y_val = tensorflow.keras.utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10,input_shape=(4,),activation='tanh'))\n",
    "model.add(Dense(8,activation='tanh'))\n",
    "model.add(Dense(6,activation='tanh'))\n",
    "model.add(Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 20 samples\n",
      "Epoch 1/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0679 - accuracy: 0.9889 - val_loss: 0.1594 - val_accuracy: 0.9000\n",
      "Epoch 2/125\n",
      "90/90 [==============================] - 0s 466us/sample - loss: 0.0677 - accuracy: 0.9889 - val_loss: 0.1743 - val_accuracy: 0.9000\n",
      "Epoch 3/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0695 - accuracy: 0.9889 - val_loss: 0.1785 - val_accuracy: 0.9000\n",
      "Epoch 4/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0676 - accuracy: 0.9889 - val_loss: 0.1605 - val_accuracy: 0.9000\n",
      "Epoch 5/125\n",
      "90/90 [==============================] - 0s 322us/sample - loss: 0.0665 - accuracy: 0.9889 - val_loss: 0.1438 - val_accuracy: 0.9500\n",
      "Epoch 6/125\n",
      "90/90 [==============================] - 0s 322us/sample - loss: 0.0681 - accuracy: 0.9889 - val_loss: 0.1351 - val_accuracy: 0.9500\n",
      "Epoch 7/125\n",
      "90/90 [==============================] - 0s 333us/sample - loss: 0.0679 - accuracy: 0.9889 - val_loss: 0.1405 - val_accuracy: 0.9500\n",
      "Epoch 8/125\n",
      "90/90 [==============================] - 0s 322us/sample - loss: 0.0673 - accuracy: 0.9889 - val_loss: 0.1617 - val_accuracy: 0.9000\n",
      "Epoch 9/125\n",
      "90/90 [==============================] - 0s 278us/sample - loss: 0.0664 - accuracy: 0.9889 - val_loss: 0.1726 - val_accuracy: 0.9000\n",
      "Epoch 10/125\n",
      "90/90 [==============================] - 0s 300us/sample - loss: 0.0670 - accuracy: 0.9889 - val_loss: 0.1633 - val_accuracy: 0.9000\n",
      "Epoch 11/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0661 - accuracy: 0.9889 - val_loss: 0.1548 - val_accuracy: 0.9500\n",
      "Epoch 12/125\n",
      "90/90 [==============================] - 0s 300us/sample - loss: 0.0656 - accuracy: 0.9889 - val_loss: 0.1501 - val_accuracy: 0.9500\n",
      "Epoch 13/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0653 - accuracy: 0.9889 - val_loss: 0.1510 - val_accuracy: 0.9500\n",
      "Epoch 14/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0655 - accuracy: 0.9889 - val_loss: 0.1543 - val_accuracy: 0.9500\n",
      "Epoch 15/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0647 - accuracy: 0.9889 - val_loss: 0.1512 - val_accuracy: 0.9500\n",
      "Epoch 16/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0659 - accuracy: 0.9889 - val_loss: 0.1423 - val_accuracy: 0.9500\n",
      "Epoch 17/125\n",
      "90/90 [==============================] - 0s 300us/sample - loss: 0.0663 - accuracy: 0.9889 - val_loss: 0.1558 - val_accuracy: 0.9500\n",
      "Epoch 18/125\n",
      "90/90 [==============================] - 0s 333us/sample - loss: 0.0657 - accuracy: 0.9889 - val_loss: 0.1484 - val_accuracy: 0.9500\n",
      "Epoch 19/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0644 - accuracy: 0.9889 - val_loss: 0.1510 - val_accuracy: 0.9500\n",
      "Epoch 20/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0653 - accuracy: 0.9889 - val_loss: 0.1662 - val_accuracy: 0.9000\n",
      "Epoch 21/125\n",
      "90/90 [==============================] - 0s 322us/sample - loss: 0.0640 - accuracy: 0.9889 - val_loss: 0.1600 - val_accuracy: 0.9000\n",
      "Epoch 22/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0636 - accuracy: 0.9889 - val_loss: 0.1508 - val_accuracy: 0.9500\n",
      "Epoch 23/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0646 - accuracy: 0.9889 - val_loss: 0.1385 - val_accuracy: 0.9500\n",
      "Epoch 24/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0651 - accuracy: 0.9889 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
      "Epoch 25/125\n",
      "90/90 [==============================] - 0s 300us/sample - loss: 0.0637 - accuracy: 0.9889 - val_loss: 0.1487 - val_accuracy: 0.9500\n",
      "Epoch 26/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0629 - accuracy: 0.9889 - val_loss: 0.1528 - val_accuracy: 0.9500\n",
      "Epoch 27/125\n",
      "90/90 [==============================] - 0s 322us/sample - loss: 0.0638 - accuracy: 0.9889 - val_loss: 0.1449 - val_accuracy: 0.9500\n",
      "Epoch 28/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0625 - accuracy: 0.9889 - val_loss: 0.1538 - val_accuracy: 0.9500\n",
      "Epoch 29/125\n",
      "90/90 [==============================] - 0s 278us/sample - loss: 0.0621 - accuracy: 0.9889 - val_loss: 0.1557 - val_accuracy: 0.9000\n",
      "Epoch 30/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0643 - accuracy: 0.9889 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
      "Epoch 31/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0621 - accuracy: 0.9889 - val_loss: 0.1600 - val_accuracy: 0.9000\n",
      "Epoch 32/125\n",
      "90/90 [==============================] - 0s 322us/sample - loss: 0.0622 - accuracy: 0.9889 - val_loss: 0.1578 - val_accuracy: 0.9000\n",
      "Epoch 33/125\n",
      "90/90 [==============================] - 0s 300us/sample - loss: 0.0631 - accuracy: 0.9889 - val_loss: 0.1510 - val_accuracy: 0.9500\n",
      "Epoch 34/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0619 - accuracy: 0.9889 - val_loss: 0.1495 - val_accuracy: 0.9500\n",
      "Epoch 35/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0627 - accuracy: 0.9889 - val_loss: 0.1616 - val_accuracy: 0.9000\n",
      "Epoch 36/125\n",
      "90/90 [==============================] - 0s 333us/sample - loss: 0.0619 - accuracy: 0.9889 - val_loss: 0.1585 - val_accuracy: 0.9000\n",
      "Epoch 37/125\n",
      "90/90 [==============================] - 0s 378us/sample - loss: 0.0640 - accuracy: 0.9889 - val_loss: 0.1341 - val_accuracy: 0.9500\n",
      "Epoch 38/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0620 - accuracy: 0.9889 - val_loss: 0.1335 - val_accuracy: 0.9500\n",
      "Epoch 39/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0621 - accuracy: 0.9889 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
      "Epoch 40/125\n",
      "90/90 [==============================] - 0s 333us/sample - loss: 0.0608 - accuracy: 0.9889 - val_loss: 0.1461 - val_accuracy: 0.9500\n",
      "Epoch 41/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0600 - accuracy: 0.9889 - val_loss: 0.1519 - val_accuracy: 0.9500\n",
      "Epoch 42/125\n",
      "90/90 [==============================] - 0s 333us/sample - loss: 0.0599 - accuracy: 0.9889 - val_loss: 0.1577 - val_accuracy: 0.9000\n",
      "Epoch 43/125\n",
      "90/90 [==============================] - 0s 322us/sample - loss: 0.0604 - accuracy: 0.9889 - val_loss: 0.1614 - val_accuracy: 0.9000\n",
      "Epoch 44/125\n",
      "90/90 [==============================] - 0s 344us/sample - loss: 0.0599 - accuracy: 0.9889 - val_loss: 0.1511 - val_accuracy: 0.9500\n",
      "Epoch 45/125\n",
      "90/90 [==============================] - 0s 278us/sample - loss: 0.0612 - accuracy: 0.9889 - val_loss: 0.1379 - val_accuracy: 0.9500\n",
      "Epoch 46/125\n",
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0606 - accuracy: 0.9889 - val_loss: 0.1485 - val_accuracy: 0.9500\n",
      "Epoch 47/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0608 - accuracy: 0.9889 - val_loss: 0.1512 - val_accuracy: 0.9500\n",
      "Epoch 48/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0590 - accuracy: 0.9889 - val_loss: 0.1462 - val_accuracy: 0.9500\n",
      "Epoch 49/125\n",
      "90/90 [==============================] - 0s 278us/sample - loss: 0.0592 - accuracy: 0.9889 - val_loss: 0.1382 - val_accuracy: 0.9500\n",
      "Epoch 50/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0591 - accuracy: 0.9889 - val_loss: 0.1397 - val_accuracy: 0.9500\n",
      "Epoch 51/125\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 1.00 - 0s 289us/sample - loss: 0.0614 - accuracy: 0.9889 - val_loss: 0.1527 - val_accuracy: 0.9500\n",
      "Epoch 52/125\n",
      "90/90 [==============================] - 0s 300us/sample - loss: 0.0588 - accuracy: 0.9889 - val_loss: 0.1482 - val_accuracy: 0.9500\n",
      "Epoch 53/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0585 - accuracy: 0.9889 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
      "Epoch 54/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0580 - accuracy: 0.9889 - val_loss: 0.1302 - val_accuracy: 0.9500\n",
      "Epoch 55/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0589 - accuracy: 0.9889 - val_loss: 0.1292 - val_accuracy: 0.9500\n",
      "Epoch 56/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 311us/sample - loss: 0.0593 - accuracy: 0.9889 - val_loss: 0.1356 - val_accuracy: 0.9500\n",
      "Epoch 57/125\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.96 - 0s 255us/sample - loss: 0.0583 - accuracy: 0.9889 - val_loss: 0.1532 - val_accuracy: 0.9500\n",
      "Epoch 58/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0586 - accuracy: 0.9889 - val_loss: 0.1640 - val_accuracy: 0.9000\n",
      "Epoch 59/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0580 - accuracy: 0.9889 - val_loss: 0.1546 - val_accuracy: 0.9000\n",
      "Epoch 60/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0571 - accuracy: 0.9889 - val_loss: 0.1433 - val_accuracy: 0.9500\n",
      "Epoch 61/125\n",
      "90/90 [==============================] - 0s 278us/sample - loss: 0.0569 - accuracy: 0.9889 - val_loss: 0.1354 - val_accuracy: 0.9500\n",
      "Epoch 62/125\n",
      "90/90 [==============================] - 0s 222us/sample - loss: 0.0578 - accuracy: 0.9889 - val_loss: 0.1275 - val_accuracy: 0.9500\n",
      "Epoch 63/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0578 - accuracy: 0.9889 - val_loss: 0.1332 - val_accuracy: 0.9500\n",
      "Epoch 64/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0569 - accuracy: 0.9889 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
      "Epoch 65/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0564 - accuracy: 0.9889 - val_loss: 0.1584 - val_accuracy: 0.9000\n",
      "Epoch 66/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0568 - accuracy: 0.9889 - val_loss: 0.1620 - val_accuracy: 0.9000\n",
      "Epoch 67/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0580 - accuracy: 0.9889 - val_loss: 0.1515 - val_accuracy: 0.9500\n",
      "Epoch 68/125\n",
      "90/90 [==============================] - 0s 222us/sample - loss: 0.0576 - accuracy: 0.9889 - val_loss: 0.1576 - val_accuracy: 0.9000\n",
      "Epoch 69/125\n",
      "90/90 [==============================] - 0s 200us/sample - loss: 0.0563 - accuracy: 0.9889 - val_loss: 0.1477 - val_accuracy: 0.9500\n",
      "Epoch 70/125\n",
      "90/90 [==============================] - 0s 222us/sample - loss: 0.0573 - accuracy: 0.9889 - val_loss: 0.1298 - val_accuracy: 0.9500\n",
      "Epoch 71/125\n",
      "90/90 [==============================] - 0s 211us/sample - loss: 0.0579 - accuracy: 0.9889 - val_loss: 0.1374 - val_accuracy: 0.9500\n",
      "Epoch 72/125\n",
      "90/90 [==============================] - 0s 222us/sample - loss: 0.0562 - accuracy: 0.9889 - val_loss: 0.1423 - val_accuracy: 0.9500\n",
      "Epoch 73/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0558 - accuracy: 0.9889 - val_loss: 0.1376 - val_accuracy: 0.9500\n",
      "Epoch 74/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0559 - accuracy: 0.9889 - val_loss: 0.1381 - val_accuracy: 0.9500\n",
      "Epoch 75/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0551 - accuracy: 0.9889 - val_loss: 0.1484 - val_accuracy: 0.9500\n",
      "Epoch 76/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0561 - accuracy: 0.9889 - val_loss: 0.1492 - val_accuracy: 0.9500\n",
      "Epoch 77/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0556 - accuracy: 0.9889 - val_loss: 0.1625 - val_accuracy: 0.9000\n",
      "Epoch 78/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0563 - accuracy: 0.9889 - val_loss: 0.1601 - val_accuracy: 0.9000\n",
      "Epoch 79/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0561 - accuracy: 0.9889 - val_loss: 0.1394 - val_accuracy: 0.9500\n",
      "Epoch 80/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0546 - accuracy: 0.9889 - val_loss: 0.1356 - val_accuracy: 0.9500\n",
      "Epoch 81/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0548 - accuracy: 0.9889 - val_loss: 0.1381 - val_accuracy: 0.9500\n",
      "Epoch 82/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0547 - accuracy: 0.9889 - val_loss: 0.1410 - val_accuracy: 0.9500\n",
      "Epoch 83/125\n",
      "90/90 [==============================] - 0s 211us/sample - loss: 0.0546 - accuracy: 0.9889 - val_loss: 0.1365 - val_accuracy: 0.9500\n",
      "Epoch 84/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0550 - accuracy: 0.9889 - val_loss: 0.1453 - val_accuracy: 0.9500\n",
      "Epoch 85/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0544 - accuracy: 0.9889 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
      "Epoch 86/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0545 - accuracy: 0.9889 - val_loss: 0.1346 - val_accuracy: 0.9500\n",
      "Epoch 87/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0551 - accuracy: 0.9889 - val_loss: 0.1423 - val_accuracy: 0.9500\n",
      "Epoch 88/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0544 - accuracy: 0.9889 - val_loss: 0.1329 - val_accuracy: 0.9500\n",
      "Epoch 89/125\n",
      "90/90 [==============================] - 0s 267us/sample - loss: 0.0568 - accuracy: 0.9889 - val_loss: 0.1462 - val_accuracy: 0.9500\n",
      "Epoch 90/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0538 - accuracy: 0.9889 - val_loss: 0.1378 - val_accuracy: 0.9500\n",
      "Epoch 91/125\n",
      "90/90 [==============================] - 0s 267us/sample - loss: 0.0550 - accuracy: 0.9889 - val_loss: 0.1299 - val_accuracy: 0.9500\n",
      "Epoch 92/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0535 - accuracy: 0.9889 - val_loss: 0.1399 - val_accuracy: 0.9500\n",
      "Epoch 93/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0530 - accuracy: 0.9889 - val_loss: 0.1489 - val_accuracy: 0.9500\n",
      "Epoch 94/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0538 - accuracy: 0.9889 - val_loss: 0.1564 - val_accuracy: 0.9000\n",
      "Epoch 95/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0537 - accuracy: 0.9889 - val_loss: 0.1506 - val_accuracy: 0.9500\n",
      "Epoch 96/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0530 - accuracy: 0.9889 - val_loss: 0.1390 - val_accuracy: 0.9500\n",
      "Epoch 97/125\n",
      "90/90 [==============================] - 0s 300us/sample - loss: 0.0540 - accuracy: 0.9889 - val_loss: 0.1178 - val_accuracy: 0.9500\n",
      "Epoch 98/125\n",
      "90/90 [==============================] - 0s 267us/sample - loss: 0.0556 - accuracy: 0.9889 - val_loss: 0.1163 - val_accuracy: 0.9500\n",
      "Epoch 99/125\n",
      "90/90 [==============================] - 0s 278us/sample - loss: 0.0544 - accuracy: 0.9889 - val_loss: 0.1374 - val_accuracy: 0.9500\n",
      "Epoch 100/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0520 - accuracy: 0.9889 - val_loss: 0.1481 - val_accuracy: 0.9500\n",
      "Epoch 101/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0522 - accuracy: 0.9889 - val_loss: 0.1578 - val_accuracy: 0.9000\n",
      "Epoch 102/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0538 - accuracy: 0.9889 - val_loss: 0.1630 - val_accuracy: 0.9000\n",
      "Epoch 103/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0530 - accuracy: 0.9889 - val_loss: 0.1404 - val_accuracy: 0.9500\n",
      "Epoch 104/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0532 - accuracy: 0.9889 - val_loss: 0.1238 - val_accuracy: 0.9500\n",
      "Epoch 105/125\n",
      "90/90 [==============================] - 0s 267us/sample - loss: 0.0555 - accuracy: 0.9889 - val_loss: 0.1187 - val_accuracy: 0.9500\n",
      "Epoch 106/125\n",
      "90/90 [==============================] - 0s 267us/sample - loss: 0.0519 - accuracy: 0.9889 - val_loss: 0.1356 - val_accuracy: 0.9500\n",
      "Epoch 107/125\n",
      "90/90 [==============================] - 0s 267us/sample - loss: 0.0543 - accuracy: 0.9889 - val_loss: 0.1676 - val_accuracy: 0.9000\n",
      "Epoch 108/125\n",
      "90/90 [==============================] - 0s 267us/sample - loss: 0.0543 - accuracy: 0.9889 - val_loss: 0.1692 - val_accuracy: 0.9000\n",
      "Epoch 109/125\n",
      "90/90 [==============================] - 0s 267us/sample - loss: 0.0529 - accuracy: 0.9889 - val_loss: 0.1386 - val_accuracy: 0.9500\n",
      "Epoch 110/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0507 - accuracy: 0.9889 - val_loss: 0.1256 - val_accuracy: 0.9500\n",
      "Epoch 111/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0538 - accuracy: 0.9889 - val_loss: 0.1134 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0531 - accuracy: 0.9889 - val_loss: 0.1232 - val_accuracy: 0.9500\n",
      "Epoch 113/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0510 - accuracy: 0.9889 - val_loss: 0.1396 - val_accuracy: 0.9500\n",
      "Epoch 114/125\n",
      "90/90 [==============================] - 0s 400us/sample - loss: 0.0520 - accuracy: 0.9889 - val_loss: 0.1562 - val_accuracy: 0.9000\n",
      "Epoch 115/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0526 - accuracy: 0.9889 - val_loss: 0.1638 - val_accuracy: 0.9000\n",
      "Epoch 116/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0533 - accuracy: 0.9889 - val_loss: 0.1565 - val_accuracy: 0.9000\n",
      "Epoch 117/125\n",
      "90/90 [==============================] - 0s 289us/sample - loss: 0.0500 - accuracy: 0.9889 - val_loss: 0.1333 - val_accuracy: 0.9500\n",
      "Epoch 118/125\n",
      "90/90 [==============================] - 0s 300us/sample - loss: 0.0534 - accuracy: 0.9889 - val_loss: 0.1103 - val_accuracy: 0.9500\n",
      "Epoch 119/125\n",
      "90/90 [==============================] - 0s 300us/sample - loss: 0.0534 - accuracy: 0.9889 - val_loss: 0.1180 - val_accuracy: 0.9500\n",
      "Epoch 120/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0527 - accuracy: 0.9889 - val_loss: 0.1322 - val_accuracy: 0.9500\n",
      "Epoch 121/125\n",
      "90/90 [==============================] - 0s 255us/sample - loss: 0.0511 - accuracy: 0.9889 - val_loss: 0.1454 - val_accuracy: 0.9500\n",
      "Epoch 122/125\n",
      "90/90 [==============================] - 0s 222us/sample - loss: 0.0503 - accuracy: 0.9889 - val_loss: 0.1426 - val_accuracy: 0.9500\n",
      "Epoch 123/125\n",
      "90/90 [==============================] - 0s 222us/sample - loss: 0.0514 - accuracy: 0.9889 - val_loss: 0.1329 - val_accuracy: 0.9500\n",
      "Epoch 124/125\n",
      "90/90 [==============================] - 0s 233us/sample - loss: 0.0505 - accuracy: 0.9889 - val_loss: 0.1377 - val_accuracy: 0.9500\n",
      "Epoch 125/125\n",
      "90/90 [==============================] - 0s 244us/sample - loss: 0.0499 - accuracy: 0.9889 - val_loss: 0.1346 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aa2e731438>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, encoded_y_train, epochs = 125, validation_data=(val_x, encoded_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
